{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90d89cc3",
   "metadata": {},
   "source": [
    "# Dataset Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b01cdc9",
   "metadata": {},
   "source": [
    "Notebook responsável por organizar os arquivos do dataset localmente\n",
    "\n",
    "Carrega as informações referente aos arquivos de dataset presente em: https://physionet.org/content/chbmit/1.0.0/\n",
    "\n",
    "Motivador: Devido ao tamanho dos arquivos e da conexão com a internet, a ideia é permitir baixar os arquivos separados e executar conforme haja tempo, permitindo retomar o download em casos de perca de conexão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0af18a",
   "metadata": {},
   "source": [
    "#### Pacotes Necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6be447",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install wfdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d8e14d",
   "metadata": {},
   "source": [
    "Armazena cada um dos diretórios presente no dataset, utilizado posteriormente para fazer o donwload separado de cada arquivo\n",
    "\n",
    "- record_list: Armazenar todos os arquivos dentro do dataset -> path/path-summary.txt + -> path/path_chxx.edf\n",
    "- part_codes: Armazena os diretórios principais de cada exame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9066dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb \n",
    "\n",
    "dbs = wfdb.get_dbs()\n",
    "records_list = wfdb.io.get_record_list('chbmit', records='all')\n",
    "\n",
    "part_codes = sorted(list(set([record.split('/')[0] for record in records_list])))\n",
    "edf_files = sorted(list(set([record.split('/')[1] for record in records_list])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469082d",
   "metadata": {},
   "source": [
    "get_summary: Faz o download de cada um dos summarios presentes nos exames e os adiciona ao path ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87360d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def get_summary( part_code ):\n",
    "  url = \"https://physionet.org/physiobank/database/chbmit/\" + part_code + '/' + part_code + '-summary.txt'\n",
    "  directory = \"../data/\" + part_code + '/'\n",
    "  filename = part_code + \"-summary.txt\"\n",
    "\n",
    "  fullpath = os.path.join( directory, filename )\n",
    "\n",
    "  if not os.path.exists( fullpath ):\n",
    "    os.makedirs( directory )\n",
    "    urlretrieve( url, fullpath )\n",
    "  else:\n",
    "    print(part_code + \": Já existe\")\n",
    "    \n",
    "#Executa\n",
    "for part_code in part_codes:\n",
    "  get_summary( part_code )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f30d6",
   "metadata": {},
   "source": [
    "get_edf_by_record: Baixar cada um dos arquivos edf's presente no dataset por exame. Arquivos já baixados, não são executados novamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e63a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "def get_edf_by_record(record, file):\n",
    "  url = \"https://physionet.org/physiobank/database/chbmit/\" + record + '/' + file\n",
    "  directory = \"../data/\" + record + '/'\n",
    "  filename = file\n",
    "\n",
    "  fullpath = os.path.join( directory, filename )\n",
    "\n",
    "  if not os.path.exists( fullpath ):\n",
    "    try:\n",
    "      urlretrieve( url, fullpath )\n",
    "      print(fullpath + \": Baixado!\")\n",
    "    except:\n",
    "      print( filename + \": Não foi possivel, verificar\")\n",
    "    \n",
    "  else:\n",
    "    print(fullpath + \": Já existe!\")\n",
    "    \n",
    "#Executa\n",
    "for record in part_codes:\n",
    "    files_by_record = list( filter( lambda file: record + '_' in file, edf_files ) )\n",
    "    for file in files_by_record:\n",
    "        get_edf_by_record( record, file )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
