{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "QTD_OF_SUMMARIES = 3\n",
    "NR_EPOCHS = 1000\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datautils.dataloader as loader\n",
    "\n",
    "summaries = loader.load_summaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\luiza\\Desktop\\Mestrado\\Trabalho\\data\\chb01\\chb01_01.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luiza\\Desktop\\Mestrado\\Trabalho\\reader\\mnereader.py:21: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  mne_model = mne.io.read_raw_edf(summary_model.fullpath(), include=commons.selected_channels(), preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\luiza\\Desktop\\Mestrado\\Trabalho\\data\\chb01\\chb01_02.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n",
      "Extracting EDF parameters from c:\\Users\\luiza\\Desktop\\Mestrado\\Trabalho\\data\\chb01\\chb01_03.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 921599  =      0.000 ...  3599.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luiza\\Desktop\\Mestrado\\Trabalho\\reader\\mnereader.py:21: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  mne_model = mne.io.read_raw_edf(summary_model.fullpath(), include=commons.selected_channels(), preload=True)\n",
      "c:\\Users\\luiza\\Desktop\\Mestrado\\Trabalho\\reader\\mnereader.py:21: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
      "  mne_model = mne.io.read_raw_edf(summary_model.fullpath(), include=commons.selected_channels(), preload=True)\n"
     ]
    }
   ],
   "source": [
    "loader.load_mne_data(summaries[:QTD_OF_SUMMARIES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.load_segmented_data(summaries[:QTD_OF_SUMMARIES])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation -> Dominio do Tempo \n",
    "\n",
    "- Segmentar as informações de tempo em janelas\n",
    "- Criar as labels para cada janela\n",
    "- Separar as informações em Treino e Teste\n",
    "- Alimentar a rede e verificar a saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datautils.splitter.mnesplitter as mnesplitter\n",
    "\n",
    "X_train, X_val, y_train, y_val = mnesplitter.segmented_time_data_splitter(summaries[:QTD_OF_SUMMARIES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2160"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1440"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ia.model.cnn as ia\n",
    "\n",
    "time_cnn = ia.CNNModel(input_shape=(X_train[0].shape[0], X_train[0].shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cnn.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 4320\n  y sizes: 1440\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\luiza\\Desktop\\Mestrado\\Trabalho\\training_time.ipynb Célula 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/luiza/Desktop/Mestrado/Trabalho/training_time.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m time_cnn\u001b[39m.\u001b[39;49mfit(X_train, y_train, num_epochs\u001b[39m=\u001b[39;49mNR_EPOCHS, batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE, val_data\u001b[39m=\u001b[39;49mX_val, val_labels\u001b[39m=\u001b[39;49my_val)\n",
      "File \u001b[1;32mc:\\Users\\luiza\\Desktop\\Mestrado\\Trabalho\\ia\\model\\cnn.py:18\u001b[0m, in \u001b[0;36mCNNModel.fit\u001b[1;34m(self, train_data, train_labels, num_epochs, batch_size, val_data, val_labels)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, train_data, train_labels, num_epochs, batch_size, val_data, val_labels):\n\u001b[1;32m---> 18\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mfit(train_data, train_labels, epochs\u001b[39m=\u001b[39;49mnum_epochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, validation_data\u001b[39m=\u001b[39;49m(val_data, val_labels))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\data_adapter.py:1950\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1943\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1944\u001b[0m         label,\n\u001b[0;32m   1945\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   1946\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1947\u001b[0m         ),\n\u001b[0;32m   1948\u001b[0m     )\n\u001b[0;32m   1949\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1950\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 4320\n  y sizes: 1440\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "time_cnn.fit(X_train, y_train, num_epochs=NR_EPOCHS, batch_size=BATCH_SIZE, val_data=X_val, val_labels=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader.load_mne_data(summaries[QTD_OF_SUMMARIES + 1:QTD_OF_SUMMARIES + 10])\n",
    "# loader.load_segmented_data(summaries[QTD_OF_SUMMARIES + 1:QTD_OF_SUMMARIES + 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# X_test = summaries[QTD_OF_SUMMARIES + 1 : QTD_OF_SUMMARIES + 10]\n",
    "# y_test = [summary.has_anomaly() for summary in X_test]\n",
    "\n",
    "# X_test_freq_data = np.array([summary.signal.get_freq_data()[0] for summary in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = time_cnn.model.predict(X_test_freq_data)\n",
    "# for i in range(len(y_test)):\n",
    "#     print(str(predictions[i]) + \":\" + str(y_test[i]))\n",
    "# test_loss, test_acc = frequency_cnn.model.evaluate(X_test_freq_data, y_test)\n",
    "\n",
    "# print(f'Test accuracy: {test_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
